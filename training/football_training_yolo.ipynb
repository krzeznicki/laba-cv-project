{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Football Opjects Detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: yellow;\">To run training of our models we need to copy this file into google colab and run it there.</span> If you want to use it in other environment, you need to change the code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q ultralytics==8.0.196\n",
    "!pip install -q roboflow\n",
    "!pip install -q torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check GPU access\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from roboflow import Roboflow\n",
    "import shutil\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "HOME = os.getcwd()\n",
    "print(HOME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colab imports\n",
    "We should use colab to train our model. However if you want to test the code locally it is possible but some functions will not be available and training will be slower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    from google.colab import userdata\n",
    "    in_colab = True\n",
    "except ImportError:\n",
    "    from dotenv import load_dotenv\n",
    "    in_colab = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_version = 1\n",
    "dataset_location = \"../data/training\"\n",
    "\n",
    "def load_dataset(model_name):\n",
    "    if in_colab:\n",
    "        rf_api_key = userdata.get(\"ROBOFLOW_API_KEY\")\n",
    "    else:\n",
    "        load_dotenv(dotenv_path='../config/.env')\n",
    "        rf_api_key = os.getenv(\"ROBOFLOW_API_KEY\")\n",
    "\n",
    "    rf = Roboflow(api_key=rf_api_key)\n",
    "    project = rf.workspace(\"k-rzeznicki\").project(\"football-players-detection-3zvbc-fynld\")\n",
    "    version = project.version(dataset_version)\n",
    "    \n",
    "    version.download(model_name, location=dataset_location)\n",
    "    print(\"loaded dataset to\", dataset_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy weights\n",
    "Deploy weights of the trained model to roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deploy_weights(model_name, results_folder, weights_filename = \"best.pt\"):\n",
    "    if in_colab:\n",
    "        rf_api_key = userdata.get(\"ROBOFLOW_API_KEY\")\n",
    "    else:\n",
    "        load_dotenv(dotenv_path='../config/.env')\n",
    "        rf_api_key = os.getenv(\"ROBOFLOW_API_KEY\")\n",
    "\n",
    "    rf = Roboflow(api_key=rf_api_key)\n",
    "    project = rf.workspace(\"k-rzeznicki\").project(\"football-players-detection-3zvbc-fynld\")\n",
    "    version = project.version(dataset_version)\n",
    "    version.deploy(model_name, results_folder, weights_filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will create a functions that will help us to train our models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Function to train yolo model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_yolo(model_name, epochs, imgsz, train_folder = None, gpu = True):\n",
    "    \"\"\"\n",
    "    This function trains a YOLO model using the specified parameters.\n",
    "\n",
    "    Parameters:\n",
    "    model_name (str): The name of the model to be trained.\n",
    "    epochs (int): The number of training epochs.\n",
    "    imgsz (int or tuple): The size of the images for training.\n",
    "    train_folder (str, optional): The folder where the training results will be saved. Defaults to None.\n",
    "    gpu (bool, optional): Flag to indicate whether to use GPU for training. Defaults to True.\n",
    "\n",
    "    Raises:\n",
    "    SystemError: If GPU is not available and gpu is set to True.\n",
    "    \"\"\"\n",
    "    # Check if GPU is available\n",
    "    if torch.cuda.is_available():\n",
    "        device = 0\n",
    "    elif torch.backends.mps.is_available() and not gpu:\n",
    "        device = \"mps\"\n",
    "    elif gpu:\n",
    "        raise SystemError('GPU device not found')\n",
    "    else:\n",
    "        device = \"cpu\"\n",
    "        \n",
    "    yolo = YOLO(model_name)\n",
    "    yolo.train(data=f'{dataset_location}/data.yaml', epochs=epochs, imgsz=imgsz, project=train_folder, name=model_name, exist_ok=True, batch=6, device=device)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(model_name, imgsz, train_folder = None, iou = 0.6, conf = 0.001, gpu = True):\n",
    "    \"\"\"\n",
    "    This function validates trained YOLO model based on our validation dataset using the specified parameters and metrics.\n",
    "\n",
    "    Parameters:\n",
    "    model_name (str): The name of the model to be validated.\n",
    "    imgsz (int or tuple): The size of the images for validation.\n",
    "    train_folder (str, optional): The folder where our dataset and .yaml file is stored. Defaults to None.\n",
    "    iou (float, optional): The Intersection over Union threshold for validation. Defaults to 0.6.\n",
    "    conf (float, optional): The confidence threshold for validation. Defaults to 0.001.\n",
    "    gpu (bool, optional): Flag to indicate whether to use GPU for validation. Defaults to True.\n",
    "\n",
    "    Raises:\n",
    "    SystemError: If GPU is not available and gpu is set to True.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary containing validation metrics such as mAP (mean Average Precision).\n",
    "    \"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = 0\n",
    "    elif torch.backends.mps.is_available() and not gpu:\n",
    "        device = \"mps\"\n",
    "    elif gpu:\n",
    "        raise SystemError('GPU device not found')\n",
    "    else:\n",
    "        device = \"cpu\"\n",
    "    \n",
    "    model = YOLO(model_name)  # load an official model\n",
    "    model = YOLO(train_folder + \"/weights/best.pt\")  # load a custom model\n",
    "\n",
    "    destination_folder = dataset_location + \"/validation\"\n",
    "    # Validate the model\n",
    "    metrics = model.val(imgsz=imgsz, data=f'{dataset_location}/data.yaml', iou=iou, conf=conf, save_json=True, plots=True, project=destination_folder, device=device)  # no arguments needed, dataset and settings remembered\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### copy trained model weights and all run files to google drive\n",
    "This function will copy all the files from the run folder to the google drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_to_drive(source_folder, destination_folder):\n",
    "    if not in_colab:\n",
    "        raise SystemError('You can copy files to drive only in Google Colab')\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    # Create the destination folder if it doesn't exist\n",
    "    os.makedirs(destination_folder, exist_ok=True)\n",
    "\n",
    "    # Copy the entire folder recursively\n",
    "    try:\n",
    "        shutil.copytree(source_folder, destination_folder, dirs_exist_ok=True)\n",
    "        print(f\"Successfully copied '{source_folder}' to '{destination_folder}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error copying folder: {e}\")\n",
    "    drive.flush_and_unmount()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose model and parameters\n",
    "model_name = \"yolov8\" # yolo11\n",
    "roboflow_name = \"yolov8\" #yolov11 # ussually the same as model name but for yolov11 the name convantion changed \n",
    "model_size = \"n\" # x\n",
    "epochs = 5 # 100\n",
    "imgsz = 180 # 1280\n",
    "project_name = \"football_analysis\"\n",
    "\n",
    "model = model_name + model_size\n",
    "train_folder = \"../runs/train/\" + project_name\n",
    "destination_folder = train_folder\n",
    "\n",
    "# load dataset\n",
    "load_dataset(roboflow_name)\n",
    "\n",
    "# train model\n",
    "train_yolo(model_name=model, epochs=epochs, imgsz=imgsz, train_folder=train_folder, gpu=False)\n",
    "\n",
    "destination_folder = destination_folder + \"/\" + model\n",
    "weights_folder = destination_folder +  \"/weights\"\n",
    "\n",
    "# deploy weights\n",
    "deploy_weights(model_name=roboflow_name, results_folder=weights_folder, weights_filename=\"best.pt\")\n",
    "\n",
    "# copy results to gooogle drive\n",
    "if in_colab:\n",
    "    drive_folder = \"/content/drive/MyDrive/Colab/\" + project_name + \"/\" + model\n",
    "    copy_to_drive(source_folder=train_folder, destination_folder=drive_folder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_model(model_name=model, imgsz=imgsz, train_folder=destination_folder, gpu=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = f'{destination_folder}/confusion_matrix.png'\n",
    "print(img_path)\n",
    "if os.path.exists(img_path):\n",
    "    img = Image.open(img_path)\n",
    "    image = mpimg.imread(img_path)\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"Image not found at {img_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = f'{destination_folder}/results.png'\n",
    "if os.path.exists(img_path):\n",
    "    img = Image.open(img_path)\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"Image not found at {img_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
